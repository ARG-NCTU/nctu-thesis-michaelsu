\chapter{文獻回顧}
\label{chapter:relate-work}

\section{亞馬遜拾取/機器人挑戰(Amazon Picking/Robotics Challanges 2015-2017)}
亞馬遜拾取挑戰 (Amazon Picking Challenge)、亞馬遜機器人挑戰 (Amazon
Robotics Challenge) 是由亞馬遜公司所創辦的大型競賽,主要目的為在
大型倉儲中商品可能高達上千種,層層排列的大型貨架,如以人力來依照訂單
集貨,不僅需要查看商品存放的位置還必須爬上貨梯進行搬運,倘若使用機器
人自動化地拾取商品,能夠大量縮短 集貨的時間。由於真實的倉儲的環境使得
機器人能活動的空間有限,且必須使機器人能夠自動辨認大量的商品種類,抓
取並放置正確的位置,對於倉儲自動化有相當大的推進。在上架任務中,物體
姿態估計是十分重要的一環,以六個自由度之物體姿態主要利用預先建制的三
維 CAD 模型,與深度攝影機所獲得的點雲(Point Cloud)進行點雲匹配如 ICP
(Iterative Closest Point) ~\cite{pomerleau2013comparing},
需以點雲資訊匹配三維模型,將實際物體的點雲從
深度攝影機所得到的原始點雲加以分離,才能獲得較好的效果,利用物體偵測
方法為將二維候選框資訊投影至三維得到物體的三維點雲,有相當大的可能引
入背景點雲進而影響 ICP 匹配結果,而採用物體語意分割(Semantic
Segmentation)的方法能夠將物體輪廓較精確的標記,將二維像素分類結果投影
至三維後能得到較單純的物體點雲,Amazon Picking Challenge 2016 競賽中
MIT-Princeton 團隊於提出的視覺系統~\cite{zeng2016multi}採用了物體語意分割與 ICP 點雲匹配的
方法。

\section{主動式視覺與主動式操作}
~\cite{sunderhauf2018limits}提及機器人視覺與電腦視覺領域的主要差異為:機器人視覺最後產出的為行動
(action)而非電腦視覺的資訊(information),電腦視覺或機器學習常以既有資
料集進行訓練,並著重於資料集的準確度提升,但機器人視覺則與環境互動,特
別關注:主動式機器人視覺(active vision)、主動式操作(active manipulation)。主
動式機器人視覺可透過機器人去控制移動攝影機,改變其位置與觀察視角,藉此去得到更多的環境資訊去改善優化機器人對環境的感知能力,改善系統的感
知信心指數、解決感知上的歧義、最小化被遮蔽的、反射等問題。主動式操作則是進一步利用會去改變場景去幫助感知的效果,例如:機器手臂可以去移動
被遮擋的物品去得到被隱藏的資訊。
這樣的概念被應用於這些研究中： \cite{atanasov2014nonmyopic} \cite{doumanoglou2016recovering} \cite{malmir2017deep}採取主動式機器人視覺的概念，採用``next-best viewpoint''的策略去改善感知的信心指數，並應用於物件偵測上。
 \cite{zeng2018robotic} 則偏向更高階的主動式操作，採取``grasp-first-then-recognize''策略去改善雜亂環境中糟糕的感知效果。
本研究就是藉由主動式操作,對於商標文字被遮蔽的物件進行操作,進而找出商標物件並正確進行上架。



\section{夾取成功率預測}
物品夾取成功率(Object affordance )對於機器人操作領域是一個重要的議題，而且其演算法往往與末端效應器（end-effector）有高度的相關。
為了處理雜亂、互相遮蔽的環境、與不同幾何形狀的物品，有許多最新的研究採取同時結合多種演算法並搭配客製化的末端效應器：
~\cite{zeng2016multi}透過經典的姿態預測：　物件模型比對（object　registration）去決定操作夾取物件的方法
~\cite{zeng2018robotic}定義4個操作方法去夾取或吸取物品，並訓練兩個全卷積網路去進行像素級別的物品夾取成功率預測
此外，也有許多研究專門研究使用兩指假爪夾取物品的物品夾取成功率： \cite{redmon2015real} 在圖片中只會有一個最佳的夾取姿態的假設，將一張彩色圖片編碼成許多網格（grid cell），並預測最終的夾取位置與姿態。另一方面，在只觀察物體的深度下，~\cite{mahler2017dex}先建立多個候選夾取姿態，定將這些姿態投影到圖片上，並預測這些夾取姿態的夾取成功率以找到最適合的夾取方法。
~\cite{pinto2016supersizing} 採取了多段的學習方法，其融合了卷積網路神經系統（CNN）與強化式學習 （reinforcement learning）去學習. \cite{zeng2018learning}透過將兩個平行的全卷積網路（一個專門訓練推，另一個專門旋練夾取）與Q-learning架構，決定現在該進行夾取或是該將原本緊密的物件們先分開再夾取的策略。以上提出的方法皆有效的改善了雜亂環境與物體互相遮蔽的問題，但卻未考慮到夾取後能否用特定姿勢去放置物品。

\section{雙機械手臂協作}
雖然機器人操作領域的問題已經被大量研究，但都僅限於單隻手臂的情況下, 關於雙手臂操作的應用研究卻較少被關注. 在Smith \textit{et al.} \cite{smith2012dual}研究中,
提出關於雙手臂應用大致可分為兩類：goal-coordinated 方法(再同個環境執行相同任務，但彼此分開行動，無任何合作), 與bimanual manipulation (對同一個物體同時進行操作).
~\cite{schwarz2018fast}便是goal-coordinated approach方法的一個典型例子，其透過兩隻手臂在雜亂盒子裡執行夾取任務，只專注於夾取物品與避免手臂之間互相碰撞，手臂間無合作，
但有效的提升夾取的效率。 而~\cite{harada2012pick} 考慮物品姿態並針對多種形狀物體進行夾取放置任務，系統透過雙手臂執行重夾動作以達到理想的放置姿態。
~\cite{miyazaki2017object}設計一個雙手臂系統，雙手臂各自有不同功能：將物品掃開解決遮蔽問題、使用吸盤假爪從雜亂的盤子中夾取物體。在Smith分類底下，本研究可被歸類為bimanual：　系統目標處理品牌文字被遮蔽的物品，透過雙手臂（一為使用吸盤假爪夾取物品至空中以便觀察，二為用兩指假爪穩定夾取並放置物體到架上）。

\section{機器人操作領域之基準訓練測試資料集}
